{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7989b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"/home/gridsan/qwang/urban-control/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7116828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_version = 2\n",
    "output_id = f\"20250416_v{prompt_version}\"\n",
    "prompt_paths = glob(f\"./data/prompts/prompts_v{prompt_version}/*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a36b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob(\"data/satellite_tiles/**/*.png\", recursive=True)\n",
    "condition_image_paths = glob(\"data/satellite_tiles_control_*/**/*.png\", recursive=True)\n",
    "zoom_level = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc17ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_name\n",
      "chicago    34340\n",
      "dallas     26915\n",
      "la         32337\n",
      "Name: image_column, dtype: int64\n",
      "91245 training samples.\n",
      "2347 validation samples.\n",
      "All descriptions with images 93592\n"
     ]
    }
   ],
   "source": [
    "if prompt_version == 2:\n",
    "    datasets = []\n",
    "\n",
    "    for prompt_path in prompt_paths:\n",
    "        city_name, x_offset, y_offset, _, _ ,_ = prompt_path.split(f'prompts_v{prompt_version}/')[1].split('_')\n",
    "        image_path_prefix = f\"data/satellite_tiles/{city_name}/{zoom_level}+{int(x_offset)}+{int(y_offset)}/\"\n",
    "        condition_path_prefix = \"data/satellite_tiles_control_{primary_landuse}/{city_name}/{zoom_level}+{x_offset}+{y_offset}/\"\n",
    "\n",
    "        def get_condition_path_prefix(row):\n",
    "            return condition_path_prefix.format(primary_landuse = row['primary_landuse'],\n",
    "                                                city_name = city_name,\n",
    "                                                zoom_level = zoom_level,\n",
    "                                                x_offset = x_offset,\n",
    "                                                y_offset = y_offset)\n",
    "\n",
    "        df = pd.read_csv(prompt_path)\n",
    "        df = df[(df['area_m2_forest']<=0.5)|(df['area_m2_forest'].isna())]\n",
    "        df = df[(df['area_m2_farmland'].isna())|(df['area_m2_farmland']<=0.5)]\n",
    "        if city_name == 'la':\n",
    "            df['random'] = np.random.rand(len(df))\n",
    "            df = df[(df['area_m2_residential']<=0.8)|(df['random']>0.5)]\n",
    "        dataset_df = df\n",
    "        dataset_df['primary_landuse'] = dataset_df['primary_landuse'].fillna(\"base\")\n",
    "        dataset_df['image_column'] = image_path_prefix + df['x'].astype(int).astype(str) + '/' + df['y'].astype(int).astype(str) + '.png'\n",
    "        dataset_df['conditioning_image_column'] = dataset_df.apply(get_condition_path_prefix, axis=1)\n",
    "        dataset_df['conditioning_image_column'] = dataset_df['conditioning_image_column'] + df['x'].astype(int).astype(str) + '/' + df['y'].astype(int).astype(str) + '.png'\n",
    "        dataset_df['caption'] = df['land_use_description']\n",
    "        dataset_df['city_name'] = city_name\n",
    "        dataset_df['x_offset'] = x_offset\n",
    "        dataset_df['y_offset'] = y_offset\n",
    "        datasets.append(dataset_df[['city_name','x','y','x_offset','y_offset','image_column', 'conditioning_image_column', 'caption']])\n",
    "\n",
    "    output_df = pd.concat(datasets)\n",
    "    output_df = output_df[output_df['image_column'].isin(image_paths)]\n",
    "    output_df = output_df[output_df['conditioning_image_column'].isin(condition_image_paths)]\n",
    "\n",
    "    print(output_df.groupby([\"city_name\"])['image_column'].count())    \n",
    "    output_df.to_csv(f'./data/train/{output_id}.csv', index=False)\n",
    "\n",
    "    output_df['random'] = np.random.rand(len(output_df))\n",
    "    train_df = output_df[output_df['random']>=0.025]\n",
    "    train_df.to_csv(f'./data/train/{output_id}_train.csv', index=False)\n",
    "    validation_df = output_df[output_df['random']<0.025]\n",
    "    validation_df.to_csv(f'./data/train/{output_id}_validation.csv', index=False)\n",
    "    print(len(train_df), \"training samples.\")\n",
    "    print(len(validation_df), \"validation samples.\")\n",
    "    print(\"All descriptions with images\", len(output_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81418520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f216997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All descriptions 54730\n",
      "All descriptions with images 11656\n"
     ]
    }
   ],
   "source": [
    "if prompt_version in (0,1,3):\n",
    "    datasets = []\n",
    "\n",
    "    for prompt_path in prompt_paths:\n",
    "        tmp = prompt_path.split(f'prompts/prompts_v{prompt_version}/')[1].split('_')\n",
    "        city_name = tmp[0]\n",
    "        x_offset = int(tmp[1])\n",
    "        y_offset = int(tmp[2])\n",
    "\n",
    "        if (y_offset == 0) | (y_offset == 5) | (x_offset == 0) | (x_offset == 5):\n",
    "            continue\n",
    "        \n",
    "        image_path_prefix = f\"data/satellite_tiles/{city_name}/{zoom_level}+{x_offset}+{y_offset}/\"\n",
    "        condition_path_prefix = f\"data/satellite_tiles_control_base/{city_name}/{zoom_level}+{x_offset}+{y_offset}/\"\n",
    "        \n",
    "        df = pd.read_csv(prompt_path)\n",
    "        if 'area_m2_forest' in df:\n",
    "            df = df[(df['area_m2_forest']<=0.5)|(df['area_m2_forest'].isna())]\n",
    "        if 'area_m2_farmland' in df:\n",
    "            df = df[(df['area_m2_farmland'].isna())|(df['area_m2_farmland']<=0.5)]\n",
    "        if city_name == 'la':\n",
    "            df['random'] = np.random.rand(len(df))\n",
    "            df = df[(df['area_m2_residential']<=0.8)|(df['random']>0.5)]\n",
    "        \n",
    "        df = df.rename(columns={'xtile':'x', 'ytile':'y', 'final_description':'land_use_description'})\n",
    "        if (prompt_version == 0) & ((x_offset != 0)|(y_offset!=0)):\n",
    "            df['x'] = df['x'].str[:5].astype(int)\n",
    "            df['y'] = df['y'].str[:5].astype(int)\n",
    "        dataset_df = df\n",
    "        dataset_df['image_column'] = image_path_prefix + dataset_df['x'].astype(str) + '/' + dataset_df['y'].astype(str) + '.png'\n",
    "        dataset_df['conditioning_image_column'] = condition_path_prefix + dataset_df['x'].astype(str) + '/' + dataset_df['y'].astype(str) + '.png'\n",
    "        dataset_df['caption'] = df['land_use_description']\n",
    "        dataset_df['city_name'] = city_name\n",
    "        dataset_df['x_offset'] = x_offset\n",
    "        dataset_df['y_offset'] = y_offset\n",
    "        datasets.append(dataset_df[['city_name','x','y','x_offset','y_offset','image_column', 'conditioning_image_column', 'caption']])\n",
    "\n",
    "    output_df = pd.concat(datasets)\n",
    "    print(\"All descriptions\", len(output_df))\n",
    "\n",
    "    output_df = output_df[output_df['image_column'].isin(image_paths)]\n",
    "    output_df = output_df[output_df['conditioning_image_column'].isin(condition_image_paths)]\n",
    "    output_df.to_csv(f'./data/train/{output_id}_append.csv', index=False)\n",
    "    print(\"All descriptions with images\", len(output_df))\n",
    "\n",
    "    output_df['random'] = np.random.rand(len(output_df))\n",
    "\n",
    "    # train_df = output_df[output_df['random']>=0.025]\n",
    "    # train_df.to_csv(f'./data/train/{output_id}_train.csv', index=False)\n",
    "    # validation_df = output_df[output_df['random']<0.025]\n",
    "    # validation_df.to_csv(f'./data/train/{output_id}_validation.csv', index=False)\n",
    "    # print(len(train_df), \"training samples.\")\n",
    "    # print(len(validation_df), \"validation samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f71a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "control"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
